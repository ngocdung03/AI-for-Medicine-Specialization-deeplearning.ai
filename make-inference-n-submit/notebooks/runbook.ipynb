{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ef5c053",
      "metadata": {
        "papermill": {
          "duration": 0.002848,
          "end_time": "2026-01-06T03:35:21.884834",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.881986",
          "status": "completed"
        },
        "tags": [],
        "id": "3ef5c053"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Ic6JDbHAIXph"
      },
      "id": "Ic6JDbHAIXph",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f46f8cc",
      "metadata": {
        "papermill": {
          "duration": 0.00149,
          "end_time": "2026-01-06T03:35:21.887999",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.886509",
          "status": "completed"
        },
        "tags": [],
        "id": "4f46f8cc"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c2fc92c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:21.892327Z",
          "iopub.status.busy": "2026-01-06T03:35:21.891944Z",
          "iopub.status.idle": "2026-01-06T03:35:21.898008Z",
          "shell.execute_reply": "2026-01-06T03:35:21.897511Z"
        },
        "papermill": {
          "duration": 0.009684,
          "end_time": "2026-01-06T03:35:21.899305",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.889621",
          "status": "completed"
        },
        "tags": [],
        "id": "8c2fc92c"
      },
      "outputs": [],
      "source": [
        "WORKING_DIR = \"/kaggle/working/\"\n",
        "CODE_DIR = \"/kaggle/temp/src\"\n",
        "GDRIVE_DIR = \"/content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jshm5WvXIdZB",
        "outputId": "638a8049-00b8-480e-f216-223a67e3dafd"
      },
      "id": "Jshm5WvXIdZB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061a8517",
      "metadata": {
        "papermill": {
          "duration": 0.001467,
          "end_time": "2026-01-06T03:35:21.902523",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.901056",
          "status": "completed"
        },
        "tags": [],
        "id": "061a8517"
      },
      "source": [
        "## Download code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BRANCH = \"ngocdung/make-inference-n-submit\""
      ],
      "metadata": {
        "id": "FFXhOBNLIv0Q"
      },
      "id": "FFXhOBNLIv0Q",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6deb560c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:21.906915Z",
          "iopub.status.busy": "2026-01-06T03:35:21.906454Z",
          "iopub.status.idle": "2026-01-06T03:35:22.809240Z",
          "shell.execute_reply": "2026-01-06T03:35:22.808363Z"
        },
        "papermill": {
          "duration": 0.906975,
          "end_time": "2026-01-06T03:35:22.811057",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.904082",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6deb560c",
        "outputId": "57fa9476-8289-4ab1-8f58-61ef875ba194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '/kaggle/temp/src'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 0), reused 10 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (16/16), 23.40 KiB | 23.40 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# If directory \"src\" not exist then clone a new one\n",
        "!pwd\n",
        "![ -d \"{CODE_DIR}\" ] || git clone --depth 1  --branch \"{BRANCH}\" \"https://github.com/aio25-mix002/m07-p7.1\" \"{CODE_DIR}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1fdc6b4",
      "metadata": {
        "papermill": {
          "duration": 0.002046,
          "end_time": "2026-01-06T03:35:22.814997",
          "exception": false,
          "start_time": "2026-01-06T03:35:22.812951",
          "status": "completed"
        },
        "tags": [],
        "id": "a1fdc6b4"
      },
      "source": [
        "## Fetch the latest code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "29c3a280",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:22.819938Z",
          "iopub.status.busy": "2026-01-06T03:35:22.819676Z",
          "iopub.status.idle": "2026-01-06T03:35:23.462681Z",
          "shell.execute_reply": "2026-01-06T03:35:23.461828Z"
        },
        "papermill": {
          "duration": 0.647535,
          "end_time": "2026-01-06T03:35:23.464347",
          "exception": false,
          "start_time": "2026-01-06T03:35:22.816812",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29c3a280",
        "outputId": "84766473-01e3-4ad5-9066-3da721bc33b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/temp/src\n",
            "Removing action-video.zip\n",
            "Removing src/__pycache__/\n",
            "On branch ngocdung/make-inference-n-submit\n",
            "Your branch is up to date with 'origin/ngocdung/make-inference-n-submit'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   train.py\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 1), reused 3 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (3/3), 1.98 KiB | 1.98 MiB/s, done.\n",
            "From https://github.com/aio25-mix002/m07-p7.1\n",
            "   de0d5d4..6ec249c  ngocdung/make-inference-n-submit -> origin/ngocdung/make-inference-n-submit\n",
            "Updating de0d5d4..6ec249c\n",
            "error: Your local changes to the following files would be overwritten by merge:\n",
            "\ttrain.py\n",
            "Please commit your changes or stash them before you merge.\n",
            "Aborting\n",
            "/kaggle/temp/src\n"
          ]
        }
      ],
      "source": [
        "# Go to CODE_DIR, Fetch the latest code\n",
        "%cd {CODE_DIR}\n",
        "!git clean -fdx\n",
        "!git status\n",
        "!git pull\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "g4QEb2HlZMiD"
      },
      "id": "g4QEb2HlZMiD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6315fe81"
      },
      "source": [
        "### Option 1: Using Kaggle API Credentials (Only if data in Google Drive not available)\n",
        "\n",
        "First, ensure you have downloaded your `kaggle.json` API token from your Kaggle account. Once downloaded, upload it to your Colab session. You can do this via the 'Files' tab on the left sidebar.\n",
        "\n",
        "After uploading, we will move it to the correct directory (`~/.kaggle/`) and set the necessary permissions."
      ],
      "id": "6315fe81"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "645da322",
        "outputId": "c817c467-1aaa-4a2f-e059-a9fdc7d83415"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create the .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Move the uploaded kaggle.json file to the .kaggle directory\n",
        "# Assuming kaggle.json is in the current working directory after upload\n",
        "# If you uploaded it to a different path, please adjust '/content/kaggle.json'\n",
        "!mv /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "# Set permissions for the kaggle.json file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print('Kaggle API credentials set up successfully!')\n",
        "!ls -la ~/.kaggle/kaggle.json"
      ],
      "id": "645da322",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API credentials set up successfully!\n",
            "-rw------- 1 root root 67 Jan  9 05:20 /root/.kaggle/kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python download_data.py\n",
        "!kaggle competitions download -c action-video\n",
        "!unzip -q action-video.zip  -d {WORKING_DIR}"
      ],
      "metadata": {
        "id": "l6odimieZMIC",
        "outputId": "468587a6-98a5-4b47-a0a2-0d8c161d4bad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading action-video.zip to /kaggle/temp/src\n",
            "100% 3.13G/3.14G [00:11<00:00, 262MB/s]\n",
            "100% 3.14G/3.14G [00:11<00:00, 286MB/s]\n",
            "replace /kaggle/working/data/data_train/brush_hair/April_09_brush_hair_u_nm_np1_ba_goo_1/10000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "id": "l6odimieZMIC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Unused due to synchronizing problem) Option 2: Using data saved in Google Drive\n"
      ],
      "metadata": {
        "id": "lmes98ROmYtp"
      },
      "id": "lmes98ROmYtp"
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# source_gdrive_data_path = os.path.join(GDRIVE_DIR, 'Data')\n",
        "# destination_working_data_path = os.path.join(WORKING_DIR, 'data')\n",
        "\n",
        "# print(f\"Attempting to copy data from Google Drive: {source_gdrive_data_path}\")\n",
        "# print(f\"To working directory: {destination_working_data_path}\")\n",
        "\n",
        "# try:\n",
        "#     # Create the destination directory if it doesn't exist. If it exists, remove it first to avoid errors.\n",
        "#     if os.path.exists(destination_working_data_path):\n",
        "#         print(f\"Destination directory {destination_working_data_path} already exists. Removing before copy...\")\n",
        "#         shutil.rmtree(destination_working_data_path)\n",
        "\n",
        "#     shutil.copytree(source_gdrive_data_path, destination_working_data_path)\n",
        "#     print(f\"Successfully copied '{source_gdrive_data_path}' to '{destination_working_data_path}'\")\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: Source data directory not found in Google Drive at {source_gdrive_data_path}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred while copying the data from Google Drive: {e}\")"
      ],
      "metadata": {
        "id": "duTIwNE6mYJ-"
      },
      "id": "duTIwNE6mYJ-",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9a407c42",
      "metadata": {
        "papermill": {
          "duration": 0.001813,
          "end_time": "2026-01-06T03:35:23.468110",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.466297",
          "status": "completed"
        },
        "tags": [],
        "id": "9a407c42"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "papermill": {
          "duration": 0.001816,
          "end_time": "2026-01-06T03:35:23.471692",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.469876",
          "status": "completed"
        },
        "tags": [],
        "outputId": "429d57ff-838e-484b-a9e7-5307deb4e4a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tt-BYnxIpHa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Initializing datasets...\n",
            "Loaded pretrained weights. Missing: 132, Unexpected: 0\n",
            "\n",
            "============================================================\n",
            "Training Configuration:\n",
            "  Epochs: 1\n",
            "  Batch size: 4\n",
            "  Learning rate: 0.0001\n",
            "  Num frames: 16\n",
            "  Frame stride: 2\n",
            "  Val ratio: 0.1\n",
            "  Checkpoint dir: ./checkpoints\n",
            "============================================================\n",
            "\n",
            "\n",
            "Epoch 1/1\n",
            "Train Loss: 3.7096 | Acc: 0.0844\n",
            "Val Loss: 3.4936   | Acc: 0.1134\n",
            "New best model saved! (0.1134)\n",
            "\n",
            "Training complete! Best validation accuracy: 0.1134\n"
          ]
        }
      ],
      "source": [
        "# Training - can change number of epochs\n",
        "!python train.py # --epochs 1"
      ],
      "id": "6tt-BYnxIpHa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the best checkpoint to Google Drive"
      ],
      "metadata": {
        "id": "Ur0NsX_WhB8s"
      },
      "id": "Ur0NsX_WhB8s"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the brief note for the filename\n",
        "NOTE = \"vanilla\" # !!! Should edit every new run\n",
        "SAVE_PATH = f\"{GDRIVE_DIR}Artifacts/Checkpoints\"\n"
      ],
      "metadata": {
        "id": "u_Bun8y2hPnQ"
      },
      "execution_count": 17,
      "outputs": [],
      "id": "u_Bun8y2hPnQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the source path of the best model checkpoint\n",
        "source_checkpoint_path = os.path.join(CODE_DIR, 'checkpoints', 'best_model.pth')\n",
        "\n",
        "# Define your Google Drive destination folder path\n",
        "# IMPORTANT: Please replace 'YOUR_GOOGLE_DRIVE_FOLDER_PATH' with the actual path to your folder in Google Drive.\n",
        "# For example, it might be '/content/drive/MyDrive/MyProjectCheckpoints/'\n",
        "\n",
        "# Ensure the Google Drive folder exists\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.makedirs(SAVE_PATH)\n",
        "    print(f\"Created Google Drive folder: {SAVE_PATH}\")\n",
        "\n",
        "# Generate a timestamp for the filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Construct the new filename for the checkpoint\n",
        "new_checkpoint_filename = f\"model_{timestamp}_{NOTE}.pth\"\n",
        "destination_checkpoint_path = os.path.join(SAVE_PATH, new_checkpoint_filename)\n",
        "\n",
        "# Copy the checkpoint\n",
        "try:\n",
        "    shutil.copy(source_checkpoint_path, destination_checkpoint_path)\n",
        "    print(f\"Checkpoint successfully saved to: {destination_checkpoint_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Source checkpoint not found at {source_checkpoint_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the checkpoint: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-mhJA7Kf7VB",
        "outputId": "85b4dfa2-3eb5-4c56-b076-407c542b7dc5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint successfully saved to: /content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/Artifacts/Checkpoints/model_20260109_054453_vanilla.pth\n"
          ]
        }
      ],
      "id": "p-mhJA7Kf7VB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reload the checkpoint (if needed)"
      ],
      "metadata": {
        "id": "fRJzvxFzhumr"
      },
      "id": "fRJzvxFzhumr"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# # Define the path to the checkpoint file\n",
        "destination_checkpoint_path = source_checkpoint_path #f'{GDRIVE_DIR}Artifacts/Checkpoints/model_20260107_081244_vanilla.pth'\n",
        "\n",
        "# Check if the checkpoint file exists\n",
        "if os.path.exists(destination_checkpoint_path):\n",
        "    # Load the checkpoint\n",
        "    loaded_checkpoint = torch.load(destination_checkpoint_path, map_location=torch.device('cpu')) # Use 'cuda' if you want to load to GPU\n",
        "    print(f\"Checkpoint loaded successfully from: {destination_checkpoint_path}\")\n",
        "    print(\"Keys in the loaded checkpoint:\", loaded_checkpoint.keys())\n",
        "\n",
        "    # Example of how you might load it into a model (assuming 'model' is defined)\n",
        "    # model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(loaded_checkpoint['optimizer_state_dict'])\n",
        "    # epoch = loaded_checkpoint['epoch']\n",
        "    # loss = loaded_checkpoint['loss']\n",
        "else:\n",
        "    print(f\"Error: Checkpoint not found at {destination_checkpoint_path}\")\n"
      ],
      "metadata": {
        "id": "l3UZYdnshyZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f22a29-0c12-45dc-90a5-cbe0cf801e83"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded successfully from: /kaggle/temp/src/checkpoints/best_model.pth\n",
            "Keys in the loaded checkpoint: odict_keys(['smif.alpha', 'smif.conv_fuse.weight', 'smif.conv_fuse.bias', 'backbone.cls_token', 'backbone.pos_embed', 'backbone.patch_embed.proj.weight', 'backbone.patch_embed.proj.bias', 'backbone.blocks.0.norm1.weight', 'backbone.blocks.0.norm1.bias', 'backbone.blocks.0.attn.qkv.weight', 'backbone.blocks.0.attn.qkv.bias', 'backbone.blocks.0.attn.proj.weight', 'backbone.blocks.0.attn.proj.bias', 'backbone.blocks.0.norm2.weight', 'backbone.blocks.0.norm2.bias', 'backbone.blocks.0.mlp.fc1.weight', 'backbone.blocks.0.mlp.fc1.bias', 'backbone.blocks.0.mlp.fc2.weight', 'backbone.blocks.0.mlp.fc2.bias', 'backbone.blocks.0.lmim.delta', 'backbone.blocks.0.lmim.reduce.weight', 'backbone.blocks.0.lmim.reduce.bias', 'backbone.blocks.0.lmim.expand.weight', 'backbone.blocks.0.lmim.expand.bias', 'backbone.blocks.0.lmim.temporal_mlp.0.weight', 'backbone.blocks.0.lmim.temporal_mlp.0.bias', 'backbone.blocks.0.lmim.temporal_mlp.1.weight', 'backbone.blocks.0.lmim.temporal_mlp.1.bias', 'backbone.blocks.0.lmim.temporal_mlp.3.weight', 'backbone.blocks.0.lmim.temporal_mlp.3.bias', 'backbone.blocks.1.norm1.weight', 'backbone.blocks.1.norm1.bias', 'backbone.blocks.1.attn.qkv.weight', 'backbone.blocks.1.attn.qkv.bias', 'backbone.blocks.1.attn.proj.weight', 'backbone.blocks.1.attn.proj.bias', 'backbone.blocks.1.norm2.weight', 'backbone.blocks.1.norm2.bias', 'backbone.blocks.1.mlp.fc1.weight', 'backbone.blocks.1.mlp.fc1.bias', 'backbone.blocks.1.mlp.fc2.weight', 'backbone.blocks.1.mlp.fc2.bias', 'backbone.blocks.1.lmim.delta', 'backbone.blocks.1.lmim.reduce.weight', 'backbone.blocks.1.lmim.reduce.bias', 'backbone.blocks.1.lmim.expand.weight', 'backbone.blocks.1.lmim.expand.bias', 'backbone.blocks.1.lmim.temporal_mlp.0.weight', 'backbone.blocks.1.lmim.temporal_mlp.0.bias', 'backbone.blocks.1.lmim.temporal_mlp.1.weight', 'backbone.blocks.1.lmim.temporal_mlp.1.bias', 'backbone.blocks.1.lmim.temporal_mlp.3.weight', 'backbone.blocks.1.lmim.temporal_mlp.3.bias', 'backbone.blocks.2.norm1.weight', 'backbone.blocks.2.norm1.bias', 'backbone.blocks.2.attn.qkv.weight', 'backbone.blocks.2.attn.qkv.bias', 'backbone.blocks.2.attn.proj.weight', 'backbone.blocks.2.attn.proj.bias', 'backbone.blocks.2.norm2.weight', 'backbone.blocks.2.norm2.bias', 'backbone.blocks.2.mlp.fc1.weight', 'backbone.blocks.2.mlp.fc1.bias', 'backbone.blocks.2.mlp.fc2.weight', 'backbone.blocks.2.mlp.fc2.bias', 'backbone.blocks.2.lmim.delta', 'backbone.blocks.2.lmim.reduce.weight', 'backbone.blocks.2.lmim.reduce.bias', 'backbone.blocks.2.lmim.expand.weight', 'backbone.blocks.2.lmim.expand.bias', 'backbone.blocks.2.lmim.temporal_mlp.0.weight', 'backbone.blocks.2.lmim.temporal_mlp.0.bias', 'backbone.blocks.2.lmim.temporal_mlp.1.weight', 'backbone.blocks.2.lmim.temporal_mlp.1.bias', 'backbone.blocks.2.lmim.temporal_mlp.3.weight', 'backbone.blocks.2.lmim.temporal_mlp.3.bias', 'backbone.blocks.3.norm1.weight', 'backbone.blocks.3.norm1.bias', 'backbone.blocks.3.attn.qkv.weight', 'backbone.blocks.3.attn.qkv.bias', 'backbone.blocks.3.attn.proj.weight', 'backbone.blocks.3.attn.proj.bias', 'backbone.blocks.3.norm2.weight', 'backbone.blocks.3.norm2.bias', 'backbone.blocks.3.mlp.fc1.weight', 'backbone.blocks.3.mlp.fc1.bias', 'backbone.blocks.3.mlp.fc2.weight', 'backbone.blocks.3.mlp.fc2.bias', 'backbone.blocks.3.lmim.delta', 'backbone.blocks.3.lmim.reduce.weight', 'backbone.blocks.3.lmim.reduce.bias', 'backbone.blocks.3.lmim.expand.weight', 'backbone.blocks.3.lmim.expand.bias', 'backbone.blocks.3.lmim.temporal_mlp.0.weight', 'backbone.blocks.3.lmim.temporal_mlp.0.bias', 'backbone.blocks.3.lmim.temporal_mlp.1.weight', 'backbone.blocks.3.lmim.temporal_mlp.1.bias', 'backbone.blocks.3.lmim.temporal_mlp.3.weight', 'backbone.blocks.3.lmim.temporal_mlp.3.bias', 'backbone.blocks.4.norm1.weight', 'backbone.blocks.4.norm1.bias', 'backbone.blocks.4.attn.qkv.weight', 'backbone.blocks.4.attn.qkv.bias', 'backbone.blocks.4.attn.proj.weight', 'backbone.blocks.4.attn.proj.bias', 'backbone.blocks.4.norm2.weight', 'backbone.blocks.4.norm2.bias', 'backbone.blocks.4.mlp.fc1.weight', 'backbone.blocks.4.mlp.fc1.bias', 'backbone.blocks.4.mlp.fc2.weight', 'backbone.blocks.4.mlp.fc2.bias', 'backbone.blocks.4.lmim.delta', 'backbone.blocks.4.lmim.reduce.weight', 'backbone.blocks.4.lmim.reduce.bias', 'backbone.blocks.4.lmim.expand.weight', 'backbone.blocks.4.lmim.expand.bias', 'backbone.blocks.4.lmim.temporal_mlp.0.weight', 'backbone.blocks.4.lmim.temporal_mlp.0.bias', 'backbone.blocks.4.lmim.temporal_mlp.1.weight', 'backbone.blocks.4.lmim.temporal_mlp.1.bias', 'backbone.blocks.4.lmim.temporal_mlp.3.weight', 'backbone.blocks.4.lmim.temporal_mlp.3.bias', 'backbone.blocks.5.norm1.weight', 'backbone.blocks.5.norm1.bias', 'backbone.blocks.5.attn.qkv.weight', 'backbone.blocks.5.attn.qkv.bias', 'backbone.blocks.5.attn.proj.weight', 'backbone.blocks.5.attn.proj.bias', 'backbone.blocks.5.norm2.weight', 'backbone.blocks.5.norm2.bias', 'backbone.blocks.5.mlp.fc1.weight', 'backbone.blocks.5.mlp.fc1.bias', 'backbone.blocks.5.mlp.fc2.weight', 'backbone.blocks.5.mlp.fc2.bias', 'backbone.blocks.5.lmim.delta', 'backbone.blocks.5.lmim.reduce.weight', 'backbone.blocks.5.lmim.reduce.bias', 'backbone.blocks.5.lmim.expand.weight', 'backbone.blocks.5.lmim.expand.bias', 'backbone.blocks.5.lmim.temporal_mlp.0.weight', 'backbone.blocks.5.lmim.temporal_mlp.0.bias', 'backbone.blocks.5.lmim.temporal_mlp.1.weight', 'backbone.blocks.5.lmim.temporal_mlp.1.bias', 'backbone.blocks.5.lmim.temporal_mlp.3.weight', 'backbone.blocks.5.lmim.temporal_mlp.3.bias', 'backbone.blocks.6.norm1.weight', 'backbone.blocks.6.norm1.bias', 'backbone.blocks.6.attn.qkv.weight', 'backbone.blocks.6.attn.qkv.bias', 'backbone.blocks.6.attn.proj.weight', 'backbone.blocks.6.attn.proj.bias', 'backbone.blocks.6.norm2.weight', 'backbone.blocks.6.norm2.bias', 'backbone.blocks.6.mlp.fc1.weight', 'backbone.blocks.6.mlp.fc1.bias', 'backbone.blocks.6.mlp.fc2.weight', 'backbone.blocks.6.mlp.fc2.bias', 'backbone.blocks.6.lmim.delta', 'backbone.blocks.6.lmim.reduce.weight', 'backbone.blocks.6.lmim.reduce.bias', 'backbone.blocks.6.lmim.expand.weight', 'backbone.blocks.6.lmim.expand.bias', 'backbone.blocks.6.lmim.temporal_mlp.0.weight', 'backbone.blocks.6.lmim.temporal_mlp.0.bias', 'backbone.blocks.6.lmim.temporal_mlp.1.weight', 'backbone.blocks.6.lmim.temporal_mlp.1.bias', 'backbone.blocks.6.lmim.temporal_mlp.3.weight', 'backbone.blocks.6.lmim.temporal_mlp.3.bias', 'backbone.blocks.7.norm1.weight', 'backbone.blocks.7.norm1.bias', 'backbone.blocks.7.attn.qkv.weight', 'backbone.blocks.7.attn.qkv.bias', 'backbone.blocks.7.attn.proj.weight', 'backbone.blocks.7.attn.proj.bias', 'backbone.blocks.7.norm2.weight', 'backbone.blocks.7.norm2.bias', 'backbone.blocks.7.mlp.fc1.weight', 'backbone.blocks.7.mlp.fc1.bias', 'backbone.blocks.7.mlp.fc2.weight', 'backbone.blocks.7.mlp.fc2.bias', 'backbone.blocks.7.lmim.delta', 'backbone.blocks.7.lmim.reduce.weight', 'backbone.blocks.7.lmim.reduce.bias', 'backbone.blocks.7.lmim.expand.weight', 'backbone.blocks.7.lmim.expand.bias', 'backbone.blocks.7.lmim.temporal_mlp.0.weight', 'backbone.blocks.7.lmim.temporal_mlp.0.bias', 'backbone.blocks.7.lmim.temporal_mlp.1.weight', 'backbone.blocks.7.lmim.temporal_mlp.1.bias', 'backbone.blocks.7.lmim.temporal_mlp.3.weight', 'backbone.blocks.7.lmim.temporal_mlp.3.bias', 'backbone.blocks.8.norm1.weight', 'backbone.blocks.8.norm1.bias', 'backbone.blocks.8.attn.qkv.weight', 'backbone.blocks.8.attn.qkv.bias', 'backbone.blocks.8.attn.proj.weight', 'backbone.blocks.8.attn.proj.bias', 'backbone.blocks.8.norm2.weight', 'backbone.blocks.8.norm2.bias', 'backbone.blocks.8.mlp.fc1.weight', 'backbone.blocks.8.mlp.fc1.bias', 'backbone.blocks.8.mlp.fc2.weight', 'backbone.blocks.8.mlp.fc2.bias', 'backbone.blocks.8.lmim.delta', 'backbone.blocks.8.lmim.reduce.weight', 'backbone.blocks.8.lmim.reduce.bias', 'backbone.blocks.8.lmim.expand.weight', 'backbone.blocks.8.lmim.expand.bias', 'backbone.blocks.8.lmim.temporal_mlp.0.weight', 'backbone.blocks.8.lmim.temporal_mlp.0.bias', 'backbone.blocks.8.lmim.temporal_mlp.1.weight', 'backbone.blocks.8.lmim.temporal_mlp.1.bias', 'backbone.blocks.8.lmim.temporal_mlp.3.weight', 'backbone.blocks.8.lmim.temporal_mlp.3.bias', 'backbone.blocks.9.norm1.weight', 'backbone.blocks.9.norm1.bias', 'backbone.blocks.9.attn.qkv.weight', 'backbone.blocks.9.attn.qkv.bias', 'backbone.blocks.9.attn.proj.weight', 'backbone.blocks.9.attn.proj.bias', 'backbone.blocks.9.norm2.weight', 'backbone.blocks.9.norm2.bias', 'backbone.blocks.9.mlp.fc1.weight', 'backbone.blocks.9.mlp.fc1.bias', 'backbone.blocks.9.mlp.fc2.weight', 'backbone.blocks.9.mlp.fc2.bias', 'backbone.blocks.9.lmim.delta', 'backbone.blocks.9.lmim.reduce.weight', 'backbone.blocks.9.lmim.reduce.bias', 'backbone.blocks.9.lmim.expand.weight', 'backbone.blocks.9.lmim.expand.bias', 'backbone.blocks.9.lmim.temporal_mlp.0.weight', 'backbone.blocks.9.lmim.temporal_mlp.0.bias', 'backbone.blocks.9.lmim.temporal_mlp.1.weight', 'backbone.blocks.9.lmim.temporal_mlp.1.bias', 'backbone.blocks.9.lmim.temporal_mlp.3.weight', 'backbone.blocks.9.lmim.temporal_mlp.3.bias', 'backbone.blocks.10.norm1.weight', 'backbone.blocks.10.norm1.bias', 'backbone.blocks.10.attn.qkv.weight', 'backbone.blocks.10.attn.qkv.bias', 'backbone.blocks.10.attn.proj.weight', 'backbone.blocks.10.attn.proj.bias', 'backbone.blocks.10.norm2.weight', 'backbone.blocks.10.norm2.bias', 'backbone.blocks.10.mlp.fc1.weight', 'backbone.blocks.10.mlp.fc1.bias', 'backbone.blocks.10.mlp.fc2.weight', 'backbone.blocks.10.mlp.fc2.bias', 'backbone.blocks.10.lmim.delta', 'backbone.blocks.10.lmim.reduce.weight', 'backbone.blocks.10.lmim.reduce.bias', 'backbone.blocks.10.lmim.expand.weight', 'backbone.blocks.10.lmim.expand.bias', 'backbone.blocks.10.lmim.temporal_mlp.0.weight', 'backbone.blocks.10.lmim.temporal_mlp.0.bias', 'backbone.blocks.10.lmim.temporal_mlp.1.weight', 'backbone.blocks.10.lmim.temporal_mlp.1.bias', 'backbone.blocks.10.lmim.temporal_mlp.3.weight', 'backbone.blocks.10.lmim.temporal_mlp.3.bias', 'backbone.blocks.11.norm1.weight', 'backbone.blocks.11.norm1.bias', 'backbone.blocks.11.attn.qkv.weight', 'backbone.blocks.11.attn.qkv.bias', 'backbone.blocks.11.attn.proj.weight', 'backbone.blocks.11.attn.proj.bias', 'backbone.blocks.11.norm2.weight', 'backbone.blocks.11.norm2.bias', 'backbone.blocks.11.mlp.fc1.weight', 'backbone.blocks.11.mlp.fc1.bias', 'backbone.blocks.11.mlp.fc2.weight', 'backbone.blocks.11.mlp.fc2.bias', 'backbone.blocks.11.lmim.delta', 'backbone.blocks.11.lmim.reduce.weight', 'backbone.blocks.11.lmim.reduce.bias', 'backbone.blocks.11.lmim.expand.weight', 'backbone.blocks.11.lmim.expand.bias', 'backbone.blocks.11.lmim.temporal_mlp.0.weight', 'backbone.blocks.11.lmim.temporal_mlp.0.bias', 'backbone.blocks.11.lmim.temporal_mlp.1.weight', 'backbone.blocks.11.lmim.temporal_mlp.1.bias', 'backbone.blocks.11.lmim.temporal_mlp.3.weight', 'backbone.blocks.11.lmim.temporal_mlp.3.bias', 'backbone.norm.weight', 'backbone.norm.bias', 'head.weight', 'head.bias'])\n"
          ]
        }
      ],
      "id": "l3UZYdnshyZf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.001777,
          "end_time": "2026-01-06T03:35:23.475387",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.473610",
          "status": "completed"
        },
        "tags": [],
        "id": "mtDjbSeWIpHc"
      },
      "source": [
        "# Submission"
      ],
      "id": "mtDjbSeWIpHc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make submission file and submit to Kaggle"
      ],
      "metadata": {
        "id": "sblI1-oItK2J"
      },
      "id": "sblI1-oItK2J"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "papermill": {
          "duration": 0.001736,
          "end_time": "2026-01-06T03:35:23.478842",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.477106",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab74e96-d1e6-449b-b0be-cb9275f68106",
        "id": "Fqun9L-mIpHd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "INFERENCE ON TEST SET\n",
            "Loading checkpoint from /kaggle/temp/src/checkpoints/best_model.pth...\n",
            "Model loaded\n",
            "\n",
            "Loading test dataset...\n",
            "Test samples: 510\n",
            "\n",
            "Running inference...\n",
            "Processed 160/510 samples\n",
            "Processed 320/510 samples\n",
            "Processed 480/510 samples\n",
            "\n",
            "Inference complete! Processed 510 videos\n",
            "Traceback (most recent call last):\n",
            "  File \"/kaggle/temp/src/inference.py\", line 141, in <module>\n",
            "    main()\n",
            "  File \"/kaggle/temp/src/inference.py\", line 137, in main\n",
            "    kaggle_submit(predicted_classes, submission_path, submit=args.submit)\n",
            "  File \"/kaggle/temp/src/inference.py\", line 18, in kaggle_submit\n",
            "    kaggle.api.competition_submit(submission_file, \"LSViT\", \"LSViT submission\")\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 874, in competition_submit\n",
            "    response = kaggle.competitions.competition_api_client.start_submission_upload(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kagglesdk/competitions/services/competition_api_service.py\", line 117, in start_submission_upload\n",
            "    return self._client.call(\"competitions.CompetitionApiService\", \"ApiStartSubmissionUpload\", request, ApiStartSubmissionUploadResponse)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kagglesdk/kaggle_http_client.py\", line 126, in call\n",
            "    response = self._prepare_response(response_type, http_response)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kagglesdk/kaggle_http_client.py\", line 191, in _prepare_response\n",
            "    http_response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/competitions/submission-url\n"
          ]
        }
      ],
      "source": [
        "# !! Remove --submit flag if don't want to submit the result\n",
        "\n",
        "!python inference.py --checkpoint {destination_checkpoint_path} \\\n",
        "    --submission_file submission.csv --submit \\\n",
        "    --data_root {WORKING_DIR}data/test\n",
        "\n",
        "\n",
        ""
      ],
      "id": "Fqun9L-mIpHd"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e5Pv32hidLSq"
      },
      "id": "e5Pv32hidLSq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 14910023,
          "sourceId": 125907,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31236,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4.587062,
      "end_time": "2026-01-06T03:35:23.698009",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2026-01-06T03:35:19.110947",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}